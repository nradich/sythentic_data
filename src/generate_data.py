"""
E-commerce Synthetic Data Generator
Uses NVIDIA Nemo Data Designer to generate realistic e-commerce datasets
"""

import os
import sys
import pandas as pd
from pathlib import Path

from client import get_data_designer_client, NEMOTRON_30B_MODEL
from schemas import DATASET_CONFIG

def generate_dataset(client, dataset_name, config):
    """Generate a single dataset using NVIDIA Nemo Data Designer"""
    
    schema = config["schema"]
    record_count = config["record_count"]
    
    print(f"Generating {record_count} records for {dataset_name} dataset...")
    
    # Create the data generation request
    # This is a simplified version - actual implementation would depend on
    # the specific Nemo Data Designer API structure
    try:
        # Construct prompt for data generation
        fields_description = []
        for field_name, field_config in schema["fields"].items():
            if field_config["type"] == "llm_generated":
                fields_description.append(f"{field_name}: {field_config['description']}")
            elif field_config["type"] == "choice":
                fields_description.append(f"{field_name}: choose from {field_config['options']}")
            elif field_config["type"] == "sequence":
                fields_description.append(f"{field_name}: {field_config['description']}")
        
        prompt = f"""
Generate {record_count} rows of synthetic data for a {schema['description']}.
Each row should contain the following fields:
{chr(10).join(['- ' + desc for desc in fields_description])}

Return the data in CSV format with headers.
Make sure the data is realistic and consistent.
"""
        
        print(f"Sending generation request to Nemotron 30B model...")
        print(f"Dataset: {dataset_name}")
        print(f"Records: {record_count}")
        
        # Note: This is a placeholder for the actual API call
        # The real implementation would use the specific Nemo Data Designer API methods
        # For now, we'll create sample data to demonstrate the structure
        
        return create_sample_data(schema, record_count)
        
    except Exception as e:
        print(f"Error generating {dataset_name} dataset: {e}")
        return None

def create_sample_data(schema, record_count):
    """Create sample data structure (placeholder for actual API response)"""
    
    sample_data = []
    
    for i in range(record_count):
        row = {}
        for field_name, field_config in schema["fields"].items():
            if field_config["type"] == "sequence":
                if "customer" in schema["name"]:
                    row[field_name] = 1001 + i
                elif "product" in schema["name"]:
                    row[field_name] = 2001 + i
                else:  # orders
                    row[field_name] = 3001 + i
            elif field_config["type"] == "choice":
                # For demo purposes, use first option
                row[field_name] = field_config["options"][i % len(field_config["options"])]
            else:
                # Placeholder for LLM generated content
                row[field_name] = f"Generated_{field_name}_{i+1}"
        
        sample_data.append(row)
    
    return sample_data

def save_to_csv(data, filename, output_dir):
    """Save generated data to CSV file"""
    
    if not data:
        print(f"No data to save for {filename}")
        return False
        
    output_path = Path(output_dir) / filename
    
    try:
        df = pd.DataFrame(data)
        df.to_csv(output_path, index=False)
        print(f"âœ… Saved {len(data)} records to {output_path}")
        return True
    except Exception as e:
        print(f"âŒ Error saving {filename}: {e}")
        return False

def main():
    """Main function to generate all e-commerce datasets"""
    
    print("ğŸš€ Starting E-commerce Synthetic Data Generation")
    print("=" * 50)
    
    # Initialize client
    try:
        client = get_data_designer_client()
        print("âœ… NVIDIA Nemo Data Designer client initialized")
    except Exception as e:
        print(f"âŒ Failed to initialize client: {e}")
        return
    
    # Create output directory
    output_dir = Path(__file__).parent.parent / "data"
    output_dir.mkdir(exist_ok=True)
    
    # Generate each dataset
    results = {}
    for dataset_name, config in DATASET_CONFIG.items():
        print(f"\nğŸ“Š Processing {dataset_name} dataset...")
        
        data = generate_dataset(client, dataset_name, config)
        
        if data:
            success = save_to_csv(data, config["filename"], output_dir)
            results[dataset_name] = success
        else:
            results[dataset_name] = False
    
    # Summary
    print("\n" + "=" * 50)
    print("ğŸ“ˆ Generation Summary:")
    for dataset_name, success in results.items():
        status = "âœ… Success" if success else "âŒ Failed"
        filename = DATASET_CONFIG[dataset_name]["filename"]
        print(f"  {dataset_name}: {status} -> {filename}")
    
    successful_datasets = sum(results.values())
    print(f"\nğŸ¯ Generated {successful_datasets}/{len(results)} datasets successfully")
    
    if successful_datasets > 0:
        print(f"ğŸ“ Output directory: {output_dir}")

if __name__ == "__main__":
    main()